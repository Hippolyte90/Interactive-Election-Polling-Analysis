# -*- coding: utf-8 -*-
"""Projet Python Data scrapers .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cWjuTkgLLmoYLIYHpMA_MKtJ-BQ0kcAi

#**Installation des packages n√©cessaires**
"""

import time # gestion des d√©lais

import requests # requ√™tes HTTP

import pandas as pd # manipulation de donn√©es

from bs4 import BeautifulSoup # analyse HTML

import numpy as np # calculs num√©riques

import re # expressions r√©guli√®res

from datetime import datetime # gestion des dates et heures

import os # interaction avec le syst√®me de fichiers

"""# **1. Collecte de donn√©es et web scraping**"""

# Liste des URLs des pages Wikip√©dia √† scraper
wiki_urls = [
    "https://en.wikipedia.org/wiki/Opinion_polling_for_the_2022_Philippine_presidential_election",
    "https://en.wikipedia.org/wiki/Opinion_polling_for_the_2016_Philippine_presidential_election",
    "https://en.wikipedia.org/wiki/Opinion_polling_for_the_2010_Philippine_presidential_election",
    "https://en.wikipedia.org/wiki/Opinion_polling_for_the_2023_Polish_parliamentary_election",
    "https://en.wikipedia.org/wiki/Opinion_polling_for_the_2019_Polish_parliamentary_election",
    "https://en.wikipedia.org/wiki/Opinion_polling_for_the_2015_Polish_parliamentary_election",
    "https://en.wikipedia.org/wiki/Opinion_polling_for_the_2011_Polish_parliamentary_election",
    "https://en.wikipedia.org/wiki/Opinion_polling_for_the_2007_Polish_parliamentary_election",
    "https://en.wikipedia.org/wiki/Opinion_polling_for_the_2005_Polish_parliamentary_election",
    "https://en.wikipedia.org/wiki/Opinion_polling_for_the_2001_Polish_parliamentary_election"
]

# Dictionnaire pour stocker les r√©sultats {nom √©lection: [df_tableau1, df_tableau2]}
scraped_data = {}

def scrape_polling_tables(url):
    start_time = time.time()

    # Extraire le nom de l'√©lection depuis l'URL
    election_name = url.split("/")[-1].replace("_", " ")

    print(f"Scraping : {election_name} ...")

    # R√©cup√©ration et parsing de la page
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()  # V√©rifie si la requ√™te a r√©ussi
    except requests.RequestException as e:
        print(f"Erreur lors de la requ√™te : {e}")
        return None

    soup = BeautifulSoup(response.text, 'html.parser')

    # Trouver tous les tableaux wikitable
    tables = soup.find_all('table', class_='wikitable')

    if len(tables) < 2:
        print(f"Moins de deux tableaux trouv√©s pour {election_name}.")
        return None

    # Liste pour stocker les DataFrames de cette page
    dataframes = []

    # Boucle pour scraper les deux premiers tableaux
    for i, table in enumerate(tables[:2]):
        rows = table.find_all('tr')

        # Extraire les en-t√™tes (premi√®re ligne)
        headers = [header.get_text(strip=True) for header in rows[0].find_all('th')]

        # Extraction des donn√©es
        data = []
        for row in rows[1:]:  # Ignorer l'en-t√™te
            cols = row.find_all(['td', 'th'])
            row_data = []

            for col in cols:
                colspan = int(col.get("colspan", 1))  # G√©rer les colonnes fusionn√©es
                rowspan = int(col.get("rowspan", 1))  # G√©rer les lignes fusionn√©es
                text = col.get_text(strip=True)


                if col.name == "td":
                   for _ in range(colspan):
                       row_data.append(text)
                else:
                    row_data.append(text)  # Ajouter normalement les <th>


            # Ajuster si le nombre de colonnes diff√®re
            if len(row_data) != len(headers):
                row_data = row_data[:len(headers)] if len(row_data) > len(headers) else row_data + [''] * (len(headers) - len(row_data))

            data.append(row_data)

        # Cr√©ation du DataFrame
        df = pd.DataFrame(data, columns=headers)
        dataframes.append(df)

    end_time = time.time()
    print(f"Scraping termin√© pour {election_name} en {end_time - start_time:.4f} secondes.\n")

    return dataframes

# Ex√©cuter le scraping sur toutes les pages
for url in wiki_urls:
    result = scrape_polling_tables(url)
    if result:
        election_name = url.split("/")[-1].replace("_", " ")
        scraped_data[election_name] = result

# Affichage des r√©sultats
for election, dfs in scraped_data.items():
    print(f"\nüîπ √âlection : {election}")
    for i, df in enumerate(dfs):
        print(f"Tableau {i+1} :")
        print(df.to_string(), "\n")

# Dictionnaire pour stocker les DataFrames
election_tables = {}

for election, dfs in scraped_data.items():
    for i, df in enumerate(dfs):
        table_name = f"{election.replace(' ', '_')}_table_{i+1}"
        election_tables[table_name] = df  # Stocker le DataFrame sous un nom unique
        print(f"‚úÖ Tableau stock√© sous le nom : {table_name}")

"""# **2. Nettoyage et traitement de donn√©es √† l'aide de pandas**

# Manipulons nos tableaux par √©lection et par pays
## Pour chacune des √©lections, les deux tableaux de donn√©es sont fusionn√©s et les colonnnes d'int√©r√™ts retenues

#**The_2022_Philippine_presidential_election**
"""

Opinion_polling_for_the_2022_Philippine_presidential_election_table_1 = pd.DataFrame(election_tables["Opinion_polling_for_the_2022_Philippine_presidential_election_table_1"])

Opinion_polling_for_the_2022_Philippine_presidential_election_table_2 = pd.DataFrame(election_tables["Opinion_polling_for_the_2022_Philippine_presidential_election_table_2"])

print(list(Opinion_polling_for_the_2022_Philippine_presidential_election_table_1.columns))

print(list(Opinion_polling_for_the_2022_Philippine_presidential_election_table_2.columns))

Philippine_2022_Presidential = pd.concat([Opinion_polling_for_the_2022_Philippine_presidential_election_table_1, Opinion_polling_for_the_2022_Philippine_presidential_election_table_2], join='inner', ignore_index=True)  # ignore_index r√©indexe proprement

Philippine_2022_Presidential = Philippine_2022_Presidential.drop(columns=['MoE', 'Ref.', 'Others', 'Und./None'], errors='ignore')

Philippine_2022_Presidential.columns = ['poll_date', 'polling_organisation', 'sample_size', 'Abella_Ind', 'De_Guzman_PLM', 'Gonzales_PDSP', 'Mangondato_Katipunan', 'Marcos_PFP', 'Montemayor_DPP', 'Moreno_Aksyon', 'Pacquiao_PROMDI', 'Robredo_Ind']

Philippine_2022_Presidential = Philippine_2022_Presidential.drop( 0 )

print(Philippine_2022_Presidential)

"""#**The_2016_Philippine_presidential_election**"""

Opinion_polling_for_the_2016_Philippine_presidential_election_table_1 = pd.DataFrame(election_tables["Opinion_polling_for_the_2016_Philippine_presidential_election_table_1"])

Opinion_polling_for_the_2016_Philippine_presidential_election_table_2 = pd.DataFrame(election_tables["Opinion_polling_for_the_2016_Philippine_presidential_election_table_2"])

print(list(Opinion_polling_for_the_2016_Philippine_presidential_election_table_1.columns))

print(list(Opinion_polling_for_the_2016_Philippine_presidential_election_table_2.columns))

Philippine_2016_Presidential = pd.concat([Opinion_polling_for_the_2016_Philippine_presidential_election_table_1, Opinion_polling_for_the_2016_Philippine_presidential_election_table_2], join='inner', ignore_index=True)  # ignore_index r√©indexe proprement

Philippine_2016_Presidential = Philippine_2016_Presidential.drop(columns=["MoE", "Refused", "Don't know"], errors='ignore')

Philippine_2016_Presidential.columns = ['polling_organisation','poll_date', 'sample_size', 'Binay_UNA', 'Poe_Ind', 'Duterte_PDP-Laban', 'Roxas_LP', 'Santiago_PRP']

Philippine_2016_Presidential = Philippine_2016_Presidential.drop( 0 )

print(Philippine_2016_Presidential)

"""#**The_2010_Philippine_presidential_election**"""

Opinion_polling_for_the_2010_Philippine_presidential_election= pd.DataFrame(election_tables["Opinion_polling_for_the_2010_Philippine_presidential_election_table_1"])

print(list(Opinion_polling_for_the_2010_Philippine_presidential_election.columns))

Philippine_2010_Presidential = Opinion_polling_for_the_2010_Philippine_presidential_election.drop(columns=["MoE", "Others/Undecided"], errors='ignore')

Philippine_2010_Presidential.columns = ['polling_organisation','poll_date', 'sample_size', 'Acosta_KBL', 'Aquino_LP', 'De_los_Reyes_AKP', 'Estrada_PMP', 'GordonB_BAYAN', 'Madrigal_Ind.', 'Perlas_Ind.', 'Teodoro_LKS-KAM', 'Villanueva_BPP', 'Villar_NP',]

Philippine_2010_Presidential = Philippine_2010_Presidential.drop([0, 1])

print(Philippine_2010_Presidential)

"""#**The_2023_Polish_parliamentary_election**"""

Opinion_polling_for_the_2023_Polish_parliamentary_election_table_1 = pd.DataFrame(election_tables["Opinion_polling_for_the_2023_Polish_parliamentary_election_table_1"])

Opinion_polling_for_the_2023_Polish_parliamentary_election_table_2 = pd.DataFrame(election_tables["Opinion_polling_for_the_2023_Polish_parliamentary_election_table_2"])

print(list(Opinion_polling_for_the_2023_Polish_parliamentary_election_table_1.columns))

print(list(Opinion_polling_for_the_2023_Polish_parliamentary_election_table_2.columns))

Polish_2023_parliamentary = pd.concat([Opinion_polling_for_the_2023_Polish_parliamentary_election_table_1, Opinion_polling_for_the_2023_Polish_parliamentary_election_table_2], join='inner', ignore_index=True)  # ignore_index r√©indexe proprement

Polish_2023_parliamentary  = Polish_2023_parliamentary .drop(columns=['Lead'], errors='ignore')

Polish_2023_parliamentary .columns = ['polling_organisation','poll_date', 'sample_size', 'United_Right', 'The_Left', 'Third_Way', 'Confederation']

Polish_2023_parliamentary = Polish_2023_parliamentary.drop([0, 1, 2,4] )

print(Polish_2023_parliamentary)

"""#**The_2019_Polish_parliamentary_election**"""

Polish_2019_parliamentary = pd.DataFrame(election_tables["Opinion_polling_for_the_2019_Polish_parliamentary_election_table_1"])

print(list(Polish_2019_parliamentary.columns))

Polish_2019_parliamentary  = Polish_2019_parliamentary .drop(columns=["Others /Don't know", 'Lead'], errors='ignore')

Polish_2019_parliamentary .columns = ['polling_organisation','poll_date', 'sample_size', 'United_Right', 'Civic_Coalition', 'The_Left', 'Polish_Coalition', 'Confederation', 'Independents& Local Gov_Activists']

Polish_2019_parliamentary = Polish_2019_parliamentary.drop([0, 1] )

print(Polish_2019_parliamentary)

"""#**The_2015_Polish_parliamentary_election**"""

Polish_2015_parliamentary = pd.DataFrame(election_tables["Opinion_polling_for_the_2015_Polish_parliamentary_election_table_1"])

print(list(Polish_2015_parliamentary.columns))

Polish_2015_parliamentary  = Polish_2015_parliamentary .drop(columns=['Others/Undecided', 'Lead'], errors='ignore')

Polish_2015_parliamentary .columns = ['poll_date','polling_organisation', 'PO', 'PiS', 'PSL', 'SLD', 'TR', "Kukiz'15", '.Nowoczesna', 'KORWiN', 'Razem']

Polish_2015_parliamentary = Polish_2015_parliamentary.drop([0] )

print(Polish_2015_parliamentary)

"""#**The_2011_Polish_parliamentary_election**"""

Polish_2011_parliamentary = pd.DataFrame(election_tables["Opinion_polling_for_the_2011_Polish_parliamentary_election_table_1"])

print(list(Polish_2011_parliamentary.columns))

Polish_2011_parliamentary  = Polish_2011_parliamentary .drop(columns=['Others/Undecided', 'Lead'], errors='ignore')

Polish_2011_parliamentary .columns = ['poll_date','polling_organisation', 'PO', 'PiS', 'SLD', 'PSL', 'RP', 'PJN']

Polish_2011_parliamentary = Polish_2011_parliamentary.drop(0 )

print(Polish_2011_parliamentary)

"""#**The_2007_Polish_parliamentary_election**"""

Polish_2007_parliamentary = pd.DataFrame(election_tables["Opinion_polling_for_the_2007_Polish_parliamentary_election_table_1"])

print(list(Polish_2007_parliamentary.columns))

Polish_2007_parliamentary  = Polish_2007_parliamentary .drop(columns=['Others', 'Undecided', 'Lead'], errors='ignore')

Polish_2007_parliamentary .columns = ['polling_organisation','poll_date', 'PiS', 'PO', 'SLD', 'UP', 'SDPL', 'PD', 'PSL', 'SRP', 'LPR']

Polish_2007_parliamentary = Polish_2007_parliamentary.drop(0)

print(Polish_2007_parliamentary)

"""#**The_2005_Polish_parliamentary_election**"""

Polish_2005_parliamentary = pd.DataFrame(election_tables["Opinion_polling_for_the_2005_Polish_parliamentary_election_table_1"])

print(list(Polish_2005_parliamentary.columns))

Polish_2005_parliamentary  = Polish_2005_parliamentary .drop(columns=["Others /Don't know", 'Lead'], errors='ignore')

Polish_2005_parliamentary .columns = ['polling_organisation','poll_date', 'SLD', 'UP', 'SDPL', 'PO', 'PiS', 'PSL', 'SRP', 'LPR', 'PD']

Polish_2005_parliamentary = Polish_2005_parliamentary.drop(0 )

print(Polish_2005_parliamentary)

"""#**The_2001_Polish_parliamentary_election**"""

Polish_2001_parliamentary = pd.DataFrame(election_tables["Opinion_polling_for_the_2001_Polish_parliamentary_election_table_1"])

print(list(Polish_2001_parliamentary.columns))

Polish_2001_parliamentary  = Polish_2001_parliamentary .drop(columns=['Others / Undecided', 'Lead'], errors='ignore')

Polish_2001_parliamentary .columns = ['poll_date','polling_organisation', 'AWS', 'SLD', 'UP', 'UW', 'PSL', 'ROP', 'SRP', 'PO', 'PiS', 'LPR']

Polish_2001_parliamentary = Polish_2001_parliamentary.drop(0)

print(Polish_2001_parliamentary)

"""#**Remodelage de toutes les bases de donn√©es**

## Le code ci-dessous transforme des bases de donn√©es √©lectorales d'un format large (o√π chaque candidat a sa propre colonne) vers un format long (o√π chaque ligne repr√©sente une pr√©diction ou un r√©sultat pour un candidat). Il identifie les variables d'identification (comme polling_organisation, poll_date, sample_size), s√©pare les r√©sultats finaux des pr√©dictions, puis les fusionne pour cr√©er un nouveau dataframe standardis√© pour chaque √©lection.
"""

# Liste des noms de bases de donn√©es √† traiter
database_names = [
    'Polish_2001_parliamentary', 'Polish_2005_parliamentary', 'Polish_2007_parliamentary',
    'Polish_2011_parliamentary', 'Polish_2015_parliamentary', 'Polish_2019_parliamentary',
    'Polish_2023_parliamentary', 'Philippine_2010_Presidential', 'Philippine_2016_Presidential',
    'Philippine_2022_Presidential'
]

# Fonction pour transformer une base de donn√©es
def transform_database(db_name, df):
    try:
        # Liste des variables d'identification possibles
        possible_id_vars = ['polling_organisation', 'poll_date', 'sample_size']

        # Identifier les variables d'identification pr√©sentes dans cette base
        id_vars = [col for col in possible_id_vars if col in df.columns]

        if not id_vars:
            print(f"Attention: Aucune variable d'identification reconnue dans {db_name}.")
            print(f"Colonnes disponibles: {df.columns.tolist()}")
            return None

        print(f"Variables d'identification utilis√©es pour {db_name}: {id_vars}")

        # Identifiez les colonnes qui sont des candidats
        candidate_cols = [col for col in df.columns if col not in id_vars]

        if not candidate_cols:
            print(f"Erreur: Aucune colonne de candidat trouv√©e dans {db_name}")
            return None

        # Utiliser l'index 0 pour les r√©sultats
        result_idx = 0

        if len(df) == 0:
            print(f"Erreur: DataFrame vide pour {db_name}")
            return None

        print(f"Ligne de r√©sultats trouv√©e √† l'index {result_idx} pour {db_name}")

        # Cr√©er un dataframe pour les r√©sultats
        results_df = df.iloc[[result_idx]].copy()
        results_long = pd.melt(
            results_df,
            id_vars=id_vars,
            value_vars=candidate_cols,
            var_name='identity_candidate',
            value_name='result'
        )

        # Cr√©er un dataframe pour les pr√©visions (toutes les lignes apr√®s la ligne de r√©sultats)
        predictions_df = df.iloc[result_idx + 1:].copy()

        # V√©rifier si nous avons des pr√©dictions
        if predictions_df.empty:
            print(f"Attention: Pas de donn√©es de pr√©diction apr√®s la ligne de r√©sultats dans {db_name}")
            return None

        predictions_long = pd.melt(
            predictions_df,
            id_vars=id_vars,
            value_vars=candidate_cols,
            var_name='identity_candidate',
            value_name='prediction'
        )

        # Fusionner les deux dataframes
        df_long = pd.merge(
            predictions_long,
            results_long[['identity_candidate', 'result']],
            on='identity_candidate',
            how='left'
        )

        print(f"Transformation r√©ussie pour {db_name}. {len(df_long)} lignes g√©n√©r√©es.")
        return df_long

    except Exception as e:
        print(f"Erreur lors du traitement de {db_name}: {str(e)}")
        return None

# Traiter toutes les bases de donn√©es et les stocker sous les m√™mes noms
successful_transformations = 0

for db_name in database_names:
    print(f"\nTraitement de {db_name}...")

    # V√©rifier si la base de donn√©es existe dans l'espace global
    if db_name in globals():
        # Sauvegarder une copie de l'original au cas o√π
        original_df = globals()[db_name].copy()

        # Transformer la base de donn√©es
        transformed_df = transform_database(db_name, original_df)

        if transformed_df is not None:
            # Stocker la version transform√©e sous le m√™me nom
            globals()[db_name] = transformed_df
            successful_transformations += 1

            print(f"Base de donn√©es {db_name} transform√©e et stock√©e avec succ√®s.")
            print(f"Aper√ßu des donn√©es transform√©es:")
            print(globals()[db_name].head(3))
        else:
            print(f"√âchec de la transformation pour {db_name}. La base originale est conserv√©e.")
    else:
        print(f"Base de donn√©es {db_name} non trouv√©e dans l'espace de travail.")

print(f"\nTraitement termin√©. {successful_transformations} bases de donn√©es transform√©es et stock√©es avec succ√®s.")

"""#**Affiliation politique de chaque candidat**

## Le code ci-dessous d√©finit un dictionnaire nomm√© political_affiliations qui associe, pour chaque √©lection (Philippines et Pologne), les candidats ou partis politiques √† leur orientation politique (gauche, centre, droite, extr√™me droite, etc.). Cette structure de donn√©es nous permettra d'attribuer automatiquement l'orientation politique √† chaque candidat dans la suite du projet.
"""

political_affiliations = {
    # Philippines 2022 Presidential
    "Philippine_2022_Presidential": {
        "Abella_Ind": "ind√©pendant",
        "De_Guzman_PLM": "gauche",  # Parti des travailleurs, orientation socialiste
        "Gonzales_PDSP": "gauche",  # Parti d√©mocrate-socialiste
        "Mangondato_Katipunan": "centre",
        "Marcos_PFP": "droite",  # Conservateur, nationaliste
        "Montemayor_DPP": "centre",
        "Moreno_Aksyon": "centre",
        "Pacquiao_PROMDI": "droite",  # Conservateur sur questions sociales
        "Robredo_Ind": "centre"  # Lib√©rale, progressiste
    },

    # Philippines 2016 Presidential
    "Philippine_2016_Presidential": {
        "Binay_UNA": "droite",
        "Poe_Ind": "centre",
        "Duterte_PDP-Laban": "droite",  # Populiste, nationaliste
        "Roxas_LP": "centre",  # Lib√©ral
        "Santiago_PRP": "centre"
    },

    # Philippines 2010 Presidential
    "Philippine_2010_Presidential": {
        "Acosta_KBL": "droite",  # Nationaliste
        "Aquino_LP": "centre",  # Lib√©ral
        "De_los_Reyes_AKP": "gauche",
        "Estrada_PMP": "gauche",  # Populiste
        "GordonB_BAYAN": "gauche",
        "Madrigal_Ind.": "centre",
        "Perlas_Ind.": "vert",  # √âcologiste
        "Teodoro_LKS-KAM": "droite",  # Conservateur
        "Villanueva_BPP": "droite",  # Chr√©tien-d√©mocrate
        "Villar_NP": "droite"  # Nationaliste
    },

    # Pologne 2023 Parliamentary
    "Polish_2023_parliamentary": {
        "United_Right": "droite",  # Coalition conservatrice
        "The_Left": "gauche",  # Coalition de gauche
        "Third_Way": "centre",  # Coalition centriste
        "Confederation": "extr√™me droite"  # Nationaliste, libertarien
    },

    # Pologne 2019 Parliamentary
    "Polish_2019_parliamentary": {
        "United_Right": "droite",  # Coalition conservatrice
        "Civic_Coalition": "centre",  # Lib√©ral
        "The_Left": "gauche",  # Coalition de gauche
        "Polish_Coalition": "droite",  # Agraire, chr√©tien-d√©mocrate
        "Confederation": "extr√™me droite",  # Nationaliste, libertarien
        "Independents& Local Gov_Activists": "divers"
    },

    # Pologne 2015 Parliamentary
    "Polish_2015_parliamentary": {
        "PO": "droite",  # Plateforme civique, lib√©ral-conservateur
        "PiS": "droite",  # Droit et Justice, conservateur
        "PSL": "droite",  # Parti paysan polonais, agraire
        "SLD": "gauche",  # Alliance de la gauche d√©mocratique
        "TR": "gauche",  # Ton Mouvement, social-lib√©ral
        "Kukiz'15": "droite",  # Populiste, anti-establishment
        ".Nowoczesna": "centre",  # Moderne, lib√©ral
        "KORWiN": "extr√™me droite",  # Libertarien, conservateur
        "Razem": "gauche"  # Ensemble, socialiste
    },

    # Pologne 2011 Parliamentary
    "Polish_2011_parliamentary": {
        "PO": "droite",  # Plateforme civique
        "PiS": "droite",  # Droit et Justice
        "SLD": "gauche",  # Alliance de la gauche d√©mocratique
        "PSL": "droite",  # Parti paysan polonais
        "RP": "centre",  # Mouvement Palikot, lib√©ral
        "PJN": "droite"  # Pologne est la plus importante, conservateur
    },

    # Pologne 2007 Parliamentary
    "Polish_2007_parliamentary": {
        "PiS": "droite",  # Droit et Justice
        "PO": "droite",  # Plateforme civique
        "SLD": "gauche",  # Alliance de la gauche d√©mocratique
        "UP": "gauche",  # Union du travail
        "SDPL": "gauche",  # Social-d√©mocratie de Pologne
        "PD": "centre",  # Parti d√©mocratique
        "PSL": "droite",  # Parti paysan polonais
        "SRP": "droite",  # Autod√©fense de la R√©publique de Pologne
        "LPR": "extr√™me droite"  # Ligue des familles polonaises
    },

    # Pologne 2005 Parliamentary
    "Polish_2005_parliamentary": {
        "SLD": "gauche",  # Alliance de la gauche d√©mocratique
        "UP": "gauche",  # Union du travail
        "SDPL": "gauche",  # Social-d√©mocratie de Pologne
        "PO": "droite",  # Plateforme civique
        "PiS": "droite",  # Droit et Justice
        "PSL": "droite",  # Parti paysan polonais
        "SRP": "droite",  # Autod√©fense de la R√©publique de Pologne
        "LPR": "extr√™me droite",  # Ligue des familles polonaises
        "PD": "centre"  # Parti d√©mocratique
    },

    # Pologne 2001 Parliamentary
    "Polish_2001_parliamentary": {
        "AWS": "droite",  # Action √©lectorale Solidarit√©
        "SLD": "gauche",  # Alliance de la gauche d√©mocratique
        "UP": "gauche",  # Union du travail
        "UW": "centre",  # Union de la libert√©
        "PSL": "droite",  # Parti paysan polonais
        "ROP": "droite",  # Mouvement pour la reconstruction de la Pologne
        "SRP": "droite",  # Autod√©fense de la R√©publique de Pologne
        "PO": "droite",  # Plateforme civique
        "PiS": "droite",  # Droit et Justice
        "LPR": "extr√™me droite"  # Ligue des familles polonaises
    }
}

"""#**Indication de l'orientation politique de chaque candidat/parti**

## La fonction add_political_leaning_column ajoute une colonne d'orientation politique √† chaque dataframe √©lectoral en associant les candidats √† leur affiliation politique d√©finie dans le dictionnaire political_affiliations. Elle v√©rifie les correspondances manquantes, les remplace par "Non d√©fini" si n√©cessaire, et retourne un dictionnaire contenant tous les dataframes mis √† jour avec cette nouvelle information.

 #    Args:
   dataframes_dict (dict): Dictionnaire contenant les dataframes des √©lections (cl√©s = noms des bases, valeurs = dataframes)
        political_affiliations (dict): Dictionnaire contenant les affiliations politiques par √©lection
        
#    Returns:
  dict: Dictionnaire mis √† jour avec les dataframes contenant la nouvelle colonne
"""

def add_political_leaning_column(dataframes_dict, political_affiliations):

    # Cr√©er une copie du dictionnaire pour ne pas modifier l'original
    updated_dfs = {}

    # Parcourir chaque dataframe
    for db_name, df in dataframes_dict.items():
        # V√©rifier si la base de donn√©es existe dans political_affiliations
        if db_name in political_affiliations:
            # Cr√©er une copie du dataframe
            updated_df = df.copy()

            # Ajouter la colonne political_leaning_candidate
            updated_df['political_leaning_candidate'] = updated_df['identity_candidate'].map(
                political_affiliations[db_name]
            )

            # Si certains candidats n'ont pas de correspondance, afficher un avertissement
            if updated_df['political_leaning_candidate'].isna().any():
                missing_candidates = updated_df[updated_df['political_leaning_candidate'].isna()]['identity_candidate'].unique()
                print(f"Attention: Les candidats suivants de {db_name} n'ont pas d'affiliation politique d√©finie: {', '.join(missing_candidates)}")
                # Remplacer les valeurs NaN par "Non d√©fini"
                updated_df['political_leaning_candidate'] = updated_df['political_leaning_candidate'].fillna("Non d√©fini")

            # Ajouter au dictionnaire de r√©sultats
            updated_dfs[db_name] = updated_df
            print(f"Colonne 'political_leaning_candidate' ajout√©e pour {db_name}")
        else:
            print(f"Attention: Aucune information politique trouv√©e pour {db_name}")
            updated_dfs[db_name] = df.copy()

    return updated_dfs

"""#**Application du code pr√©c√©dent sur nos donn√©es**

##Ce code cr√©e un dictionnaire election_dataframes contenant tous les dataframes √©lectoraux, applique la fonction add_political_leaning_column pour ajouter l'orientation politique √† chaque candidat, puis remplace les dataframes originaux par leurs versions mises √† jour avec cette nouvelle colonne d'affiliation politique.
"""

# Cr√©er un dictionnaire avec vos dataframes
election_dataframes = {
    "Polish_2001_parliamentary": Polish_2001_parliamentary,
    "Polish_2005_parliamentary": Polish_2005_parliamentary,
    "Polish_2007_parliamentary": Polish_2007_parliamentary,
    "Polish_2011_parliamentary": Polish_2011_parliamentary,
    "Polish_2015_parliamentary": Polish_2015_parliamentary,
    "Polish_2019_parliamentary": Polish_2019_parliamentary,
    "Polish_2023_parliamentary": Polish_2023_parliamentary,
    "Philippine_2010_Presidential": Philippine_2010_Presidential,
    "Philippine_2016_Presidential": Philippine_2016_Presidential,
    "Philippine_2022_Presidential": Philippine_2022_Presidential
}

# Appliquer la fonction pour ajouter la colonne political_leaning_candidate
updated_dataframes = add_political_leaning_column(election_dataframes, political_affiliations)

# Si vous souhaitez remplacer vos dataframes originaux par les versions mises √† jour
Polish_2001_parliamentary = updated_dataframes["Polish_2001_parliamentary"]
Polish_2005_parliamentary = updated_dataframes["Polish_2005_parliamentary"]
Polish_2007_parliamentary = updated_dataframes["Polish_2007_parliamentary"]
Polish_2011_parliamentary = updated_dataframes["Polish_2011_parliamentary"]
Polish_2015_parliamentary = updated_dataframes["Polish_2015_parliamentary"]
Polish_2019_parliamentary = updated_dataframes["Polish_2019_parliamentary"]
Polish_2023_parliamentary = updated_dataframes["Polish_2023_parliamentary"]
Philippine_2010_Presidential = updated_dataframes["Philippine_2010_Presidential"]
Philippine_2016_Presidential = updated_dataframes["Philippine_2016_Presidential"]
Philippine_2022_Presidential = updated_dataframes["Philippine_2022_Presidential"]

#Affichage des donn√©es
Polish_2001_parliamentary.head(20)
Polish_2001_parliamentary.head(20)
Polish_2005_parliamentary.head(20)
Polish_2007_parliamentary.head(20)
Polish_2011_parliamentary.head(20)
Polish_2015_parliamentary.head(20)
Polish_2019_parliamentary.head(20)
Polish_2023_parliamentary.head(20)
Philippine_2010_Presidential.head(20)
Philippine_2016_Presidential.head(20)
Philippine_2022_Presidential.head(20)

"""#**D√©tection des outliers**

Cette fonction identifie les valeurs statistiquement aberrantes dans les donn√©es √©lectorales en utilisant principalement la m√©thode du score Z. Elle parcourt chaque dataframe et chaque colonne num√©rique pour d√©tecter les valeurs qui s'√©cartent significativement de la moyenne (au-del√† d'un seuil d√©fini, ici de 3 √©carts-types), marque les lignes contenant des valeurs aberrantes avec un indicateur has_outlier. Les r√©sultats sont conserv√©s dans les dataframes originaux tout en marquant les outliers

   Param√®tres:
    - final_cleaned_dataframes: Dictionnaire de DataFrames d√©j√† nettoy√©s
    - method: M√©thode de d√©tection des outliers ('zscore')
    - threshold: Seuil pour la d√©tection (3)

  Retourne:
    - Dictionnaire de DataFrames avec outliers identifi√©s
    - R√©sum√© des outliers d√©tect√©s
"""

def detect_and_handle_outliers(updated_dataframes, method='zscore', threshold=3):

    final_dataframes = {}
    outlier_summary = {}

    for name, df in updated_dataframes.items():
        print(f"\nAnalyse des outliers pour {name}:")

        # Copie du DataFrame pour √©viter de modifier l'original
        df_clean = df.copy()

        # 1. Identifier les colonnes num√©riques (celles qui contiennent des pourcentages √©lectoraux)
        non_numeric_cols = ['poll_date', 'polling_organisation', 'sample_size', 'identity_candidate', 'political_leaning_candidate']
        # Filtrer pour ne garder que les colonnes qui existent r√©ellement dans le dataframe
        existing_non_numeric = [col for col in non_numeric_cols if col in df_clean.columns]
        numeric_cols = [col for col in df_clean.columns if col not in existing_non_numeric]

        # 2. Convertir les colonnes num√©riques en type num√©rique si ce n'est pas d√©j√† le cas
        for col in numeric_cols:
            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')

        # 3. Cr√©er un DataFrame pour stocker les informations sur les outliers
        outlier_info = pd.DataFrame(index=df_clean.index)

        # 4. D√©tecter les outliers pour chaque colonne num√©rique
        for col in numeric_cols:
            # Ignorer les colonnes avec trop de valeurs manquantes
            if df_clean[col].isna().sum() > len(df_clean) * 0.5:
                continue

            if method == 'zscore':
                # M√©thode Z-score
                mean = df_clean[col].mean()
                std = df_clean[col].std()

                if std == 0:  # √âviter division par z√©ro
                    continue

                z_scores = (df_clean[col] - mean) / std
                outliers = abs(z_scores) > threshold #prend la valeur absolue du score Z
                outlier_info[f'{col}_outlier'] = outliers

                print(f"  Colonne {col}: {outliers.sum()} outliers d√©tect√©s")
                print(f"    Limites Z-score: [-{threshold}, {threshold}]")


            else:
                raise ValueError(f"M√©thode de d√©tection '{method}' non reconnue. Utilisez 'zscore'.")

        # 5. Ajouter une colonne indiquant si une ligne contient au moins un outlier
        if not outlier_info.empty:
            outlier_info['has_outlier'] = outlier_info.any(axis=1)

            # 6. Fusionner l'information sur les outliers avec le DataFrame original
            df_clean['has_outlier'] = outlier_info['has_outlier']

            # 7. Afficher des statistiques sur les outliers
            total_outliers = outlier_info['has_outlier'].sum()
            print(f"Total des lignes avec au moins un outlier: {total_outliers} ({total_outliers/len(df_clean)*100:.2f}%)")

            # 8. Cr√©er un r√©sum√© des outliers pour ce DataFrame
            outlier_summary[name] = {
                'total_rows': len(df_clean),
                'rows_with_outliers': total_outliers,
                'percentage': total_outliers/len(df_clean)*100 if len(df_clean) > 0 else 0,
                'outliers_by_column': {col: outlier_info[f'{col}_outlier'].sum() for col in numeric_cols
                                      if f'{col}_outlier' in outlier_info.columns}
            }
        else:
            # Cas o√π aucune colonne num√©rique n'a √©t√© analys√©e
            df_clean['has_outlier'] = False
            outlier_summary[name] = {
                'total_rows': len(df_clean),
                'rows_with_outliers': 0,
                'percentage': 0,
                'outliers_by_column': {}
            }
            print("Aucun outlier d√©tect√© ou aucune colonne num√©rique valide pour l'analyse.")

        # 9. Stocker les diff√©rentes versions du DataFrame
        final_dataframes[name] = {
            'original': df_clean,  # Avec marquage des outliers
            # Vous pourriez ajouter d'autres versions ici, comme:
            # 'no_outliers': df_clean[~df_clean['has_outlier']],  # Sans les outliers
            # 'capped': df_capped  # Avec les outliers plafonn√©s
        }

    # 10. Cr√©er un rapport de synth√®se sur les outliers
    print("\nRapport de synth√®se sur les outliers:")
    for name, summary in outlier_summary.items():
        print(f"{name}: {summary['rows_with_outliers']} lignes avec outliers ({summary['percentage']:.2f}%)")
        if summary['outliers_by_column']:
            print("  D√©tail par colonne:")
            for col, count in summary['outliers_by_column'].items():
                print(f"    {col}: {count} outliers")

    return final_dataframes, outlier_summary


outlier_dataframes, outlier_summary = detect_and_handle_outliers(updated_dataframes, method='zscore', threshold=3)


# Afficher les premi√®res lignes de chaque DataFrame original (avec outliers identifi√©s)
print ( "\nAper√ßu des DataFrames avec outliers identifi√©s pour toutes les √©lections:" )
for Election_name, df_dict in outlier_dataframes.items():
     print ( f"\n { '-' * 80 } \n {Election_name} :\n { '-' * 80 } " )
     print (df_dict[ 'original' ].head())

"""#**Cr√©ation d'un fichier Excel pour chaque √©lection**

##Le code suivant extrait les informations de chaque nom d'√©lection (pays, ann√©e, type). Il cr√©e ensuite des fichiers Excel standardis√©s pour chaque √©lection dans un format uniforme avec des colonnes pour la date du sondage, l'organisation de sondage, et pour chaque candidat: pr√©diction, r√©sultat final, identit√© et orientation politique. Enfin, il sauvegarde ces donn√©es standardis√©es dans des fichiers Excel organis√©s dans un r√©pertoire "election_files".
"""

# Liste des √©lections
elections = [
    'Polish_2001_parliamentary', 'Polish_2005_parliamentary', 'Polish_2007_parliamentary',
    'Polish_2011_parliamentary', 'Polish_2015_parliamentary', 'Polish_2019_parliamentary',
    'Polish_2023_parliamentary', 'Philippine_2010_Presidential', 'Philippine_2016_Presidential',
    'Philippine_2022_Presidential'
]

# Fonction pour extraire les informations du nom de l'√©lection
def extract_info(election_name):
    parts = election_name.split('_')
    country = parts[0]
    year = parts[1]
    election_type = parts[2]
    return country, year, election_type

# Fonction pour cr√©er un fichier Excel standardis√© pour chaque √©lection
def create_standardized_excel(election_name, election_data, output_dir='election_files'):
    # Extraire les informations du nom de l'√©lection
    country, year, election_type = extract_info(election_name)

    # Cr√©er le r√©pertoire de sortie s'il n'existe pas
    os.makedirs(output_dir, exist_ok=True)

    # Nom du fichier standardis√©
    filename = f"{country}_{year}_{election_type}.xlsx"
    filepath = os.path.join(output_dir, filename)

    # V√©rifier la structure de election_data
    print(f"Type de donn√©es pour {election_name}: {type(election_data)}")

    # Si election_data est un dictionnaire, essayons de trouver le DataFrame
    if isinstance(election_data, dict):
        # Chercher un DataFrame dans les valeurs du dictionnaire
        df_found = False
        for key, value in election_data.items():
            if isinstance(value, pd.DataFrame):
                election_df = value
                df_found = True
                print(f"DataFrame trouv√© sous la cl√© '{key}' pour {election_name}")
                break

        if not df_found:
            # Si aucun DataFrame n'est trouv√© directement, cherchons plus profond√©ment
            for key, value in election_data.items():
                if isinstance(value, dict):
                    for subkey, subvalue in value.items():
                        if isinstance(subvalue, pd.DataFrame):
                            election_df = subvalue
                            df_found = True
                            print(f"DataFrame trouv√© sous les cl√©s '{key}.{subkey}' pour {election_name}")
                            break
                if df_found:
                    break

        if not df_found:
            print(f"Aucun DataFrame trouv√© pour {election_name}")
            # Cr√©er un DataFrame vide avec les colonnes attendues
            election_df = pd.DataFrame(columns=[
                'poll_date', 'polling_organisation', 'identity_candidate',
                'prediction', 'result', 'political_leaning_candidate'
            ])
    elif isinstance(election_data, pd.DataFrame):
        election_df = election_data
    else:
        print(f"Type de donn√©es non pris en charge pour {election_name}: {type(election_data)}")
        return

    # Afficher les colonnes disponibles pour le d√©bogage
    print(f"Colonnes disponibles pour {election_name}: {election_df.columns.tolist()}")

    # V√©rifier si les colonnes n√©cessaires existent
    required_columns = ['poll_date', 'polling_organisation', 'identity_candidate', 'prediction', 'result', 'political_leaning_candidate']
    missing_columns = [col for col in required_columns if col not in election_df.columns]

    if missing_columns:
        print(f"Colonnes manquantes pour {election_name}: {missing_columns}")
        # Ajouter les colonnes manquantes avec des valeurs NaN
        for col in missing_columns:
            election_df[col] = pd.NA

    # Identifier les candidats uniques
    candidates = election_df['identity_candidate'].unique()
    print(f"Candidats identifi√©s pour {election_name}: {candidates}")

    # Cr√©er un nouveau DataFrame pour stocker les donn√©es restructur√©es
    new_df = pd.DataFrame()

    # Ajouter les colonnes communes
    new_df['poll_date'] = election_df['poll_date'].unique()

    # V√©rifier si sample_size existe et l'ajouter si disponible
    if 'sample_size' in election_df.columns:
        # Supposons que sample_size est le m√™me pour tous les candidats d'un m√™me sondage
        sample_sizes = {}
        for date in new_df['poll_date']:
            date_df = election_df[election_df['poll_date'] == date]
            if not date_df.empty:
                sample_sizes[date] = date_df['sample_size'].iloc[0]
            else:
                sample_sizes[date] = None
        new_df['sample_size'] = [sample_sizes.get(date) for date in new_df['poll_date']]

    # Ajouter polling_organisation si disponible
    orgs = {}
    for date in new_df['poll_date']:
        date_df = election_df[election_df['poll_date'] == date]
        if not date_df.empty:
            orgs[date] = date_df['polling_organisation'].iloc[0]
        else:
            orgs[date] = None
    new_df['polling_organization'] = [orgs.get(date) for date in new_df['poll_date']]

    # Pr√©parer les colonnes pour tous les candidats d'abord
    for i, candidate in enumerate(candidates, 1):
        candidate_df = election_df[election_df['identity_candidate'] == candidate]

        # Initialiser les colonnes pour ce candidat
        new_df[f'prediction_result_candidate{i}'] = None
        new_df[f'final_result_candidate{i}'] = None
        new_df[f'identity_candidate{i}'] = candidate
        new_df[f'political_leaning_candidate{i}'] = None

        if not candidate_df.empty:
            # R√©sultat final (le m√™me pour toutes les lignes)
            new_df[f'final_result_candidate{i}'] = candidate_df['result'].iloc[0]
            # Orientation politique (la m√™me pour toutes les lignes)
            new_df[f'political_leaning_candidate{i}'] = candidate_df['political_leaning_candidate'].iloc[0]

            # Pour chaque date de sondage, trouver la pr√©diction pour ce candidat
            for idx, date in enumerate(new_df['poll_date']):
                candidate_date_df = candidate_df[candidate_df['poll_date'] == date]
                if not candidate_date_df.empty:
                    new_df.at[idx, f'prediction_result_candidate{i}'] = candidate_date_df['prediction'].iloc[0]

    # R√©organiser les colonnes dans l'ordre sp√©cifi√©
    columns = ['poll_date']

    # Ajouter sample_size si disponible
    if 'sample_size' in new_df.columns:
        columns.append('sample_size')

    # Ajouter polling_organization si disponible
    if 'polling_organization' in new_df.columns:
        columns.append('polling_organization')

    # Ajouter les colonnes pour chaque candidat dans l'ordre sp√©cifi√©
    for i in range(1, len(candidates) + 1):
        columns.extend([
            f'prediction_result_candidate{i}',
            f'final_result_candidate{i}',
            f'identity_candidate{i}',
            f'political_leaning_candidate{i}'
        ])

    # R√©organiser le DataFrame
    new_df = new_df[columns]

    # Sauvegarder le DataFrame restructur√© dans un fichier Excel
    new_df.to_excel(filepath, index=False)
    print(f"Fichier cr√©√©: {filepath}")

# V√©rifier si outlier_dataframes existe, sinon le cr√©er comme un dictionnaire vide
try:
    outlier_dataframes
except NameError:
    print("Variable 'outlier_dataframes' non d√©finie. Cr√©ation d'un dictionnaire vide.")
    outlier_dataframes = {}

# Cr√©er un fichier Excel standardis√© pour chaque √©lection
for election_name in elections:
    if election_name in outlier_dataframes:
        try:
            create_standardized_excel(election_name, outlier_dataframes[election_name])
        except Exception as e:
            print(f"Erreur lors du traitement de {election_name}: {str(e)}")
    else:
        print(f"Attention: {election_name} n'est pas pr√©sent dans outlier_dataframes")

# Cr√©ation et modification des fichiers durant l'execution:
print("Fichiers cr√©√©s:")
for election_name in elections:
    country, year, election_type = extract_info(election_name)
    print(f"election_files/{country}_{year}_{election_type}.xlsx")

"""#**Standardisation des dates et gestion des valeurs manquantes**"""

def standardize_poll_date(df):
       def clean_date1(date_str):
        # Remplacer les underscores par des espaces
        date_str = date_str.replace("_", " ")

        # Extraire les nombres pr√©sents dans la cha√Æne
        numbers = re.findall(r'\d+', date_str)

        # Garder les deux derniers nombres si plus d'un est trouv√©, sinon garder le seul nombre trouv√©
        if len(numbers) >= 2:
            numbers = numbers[-2:]
        elif len(numbers) == 1:
            numbers = numbers

        # Extraire les trois premi√®res lettres du mois si pr√©sentes
        text_match = re.search(r'[a-zA-Z]{3}', date_str)
        month_abbr = text_match.group(0) if text_match else ""

        # Construire la nouvelle date format√©e
        standardized_date = " ".join([month_abbr] + numbers)

        return standardized_date.strip()

    # Appliquer la transformation sur la colonne "poll_date"
       if "poll_date" in df.columns:
        df["poll_date"] = df["poll_date"].astype(str).apply(clean_date1)

       return df

def clean_poll_date(df, df_name):
    # Extraire l'ann√©e (4 chiffres) du nom du dataframe
    year_match = re.search(r'\d{4}', df_name)
    year = year_match.group(0) if year_match else "Unknown"

    def clean_date2(date_str):
        # V√©rifier si la valeur est valide
        if not isinstance(date_str, str) or date_str.strip() == "":
            return date_str

        # Compter les espaces
        space_count = date_str.count(" ")

        # Si la ligne contient deux espaces, supprimer les nombres apr√®s le deuxi√®me espace
        if space_count == 2:
            parts = date_str.split(" ")
            date_str = " ".join(parts[:2])  # Garder uniquement les deux premiers √©l√©ments

        # Ajouter l'ann√©e extraite du nom du dataframe
        date_str = f"{date_str} {year}"
        return date_str.strip()

    # Appliquer la transformation sur la colonne "poll_date"
    if "poll_date" in df.columns:
        df["poll_date"] = df["poll_date"].astype(str).apply(clean_date2)
    return df

# Fonction pour nettoyer la colonne "polling_organization" et remplacer les valeurs manquantes
def clean_poll_org(df):
    """
    Fonction pour nettoyer la colonne "polling_organization" et remplacer les valeurs manquantes dans tout le dataframe.

    Args:
        df (pd.DataFrame): Le dataframe contenant la colonne "polling_organization".

    Returns:
        pd.DataFrame: Le dataframe avec la colonne nettoy√©e et les valeurs manquantes remplac√©es par 0.
    """
    def extract_org_name(org_str):
        """Extrait le nom de l'organisation avant '/' ou '[' """
        if not isinstance(org_str, str):
            return org_str  # Retourner tel quel si ce n'est pas une cha√Æne
        return re.split(r'\/|\[', org_str)[0].strip()  # Prendre avant '/' ou '['

    # Appliquer la transformation sur "polling_organization"
    if "polling_organization" in df.columns:
        df["polling_organization"] = df["polling_organization"].astype(str).apply(extract_org_name)

    # Remplacer toutes les valeurs manquantes par 0
    df.fillna(0, inplace=True)

    return df

def organize_data(df):
    """
    - V√©rifie et nettoie la colonne 'poll_date'.
    - Convertit 'poll_date' en format datetime.
    - Trie les donn√©es par date.
    - Retourne le DataFrame modifi√©.
    """
    # Supprimer les espaces en trop et uniformiser les dates
    df['poll_date'] = df['poll_date'].astype(str).str.strip()

    # V√©rifier si la colonne contient d√©j√† des dates au format diff√©rent
    df['poll_date'] = pd.to_datetime(df['poll_date'], errors='coerce')
    # Trier par date apr√®s conversion
    df = df.sort_values(by='poll_date')
    df = df.dropna()
    return df

def date_manipulate(df, file_name):
    df = standardize_poll_date(df)
    df = clean_poll_date(df, file_name)
    df = clean_poll_org(df)
    df = organize_data(df)
    return df

data = {
        "2022": "election_files/Philippine_2022_Presidential.xlsx",
        "2016": "election_files/Philippine_2016_Presidential.xlsx",
        "2010": "election_files/Philippine_2010_Presidential.xlsx",
        "2023": "election_files/Polish_2023_parliamentary.xlsx",
        "2019": "election_files/Polish_2019_parliamentary.xlsx",
        "2015": "election_files/Polish_2015_parliamentary.xlsx",
        "2011": "election_files/Polish_2011_parliamentary.xlsx",
        "2007": "election_files/Polish_2007_parliamentary.xlsx",
        "2005": "election_files/Polish_2005_parliamentary.xlsx",
        "2001": "election_files/Polish_2001_parliamentary.xlsx"
}


# Boucle pour lire chaque fichier Excel
for year, file_name in data.items():
    try:
        # Lire le fichier Excel dans un DataFrame
        df = pd.read_excel(file_name)
        df = date_manipulate(df, file_name)
        df.to_excel(file_name, index=False)
        # Afficher les premi√®res lignes du DataFrame
        print(f"{year}: Lecture termin√©e pour {file_name}")
        print(df.head())
    except Exception as e:
        print(f"Erreur lors de la lecture du fichier {file_name}: {e}")

"""Ce code pr√©pare le dataframe pour l'analyse et la visualisation en appliquant plusieurs transformations :
    - Supprime les colonnes inutiles.
    - Stocke les valeurs uniques des colonnes d'identit√© et d'affiliation politique.
    - Remplace temporairement ces valeurs par des identifiants num√©riques.
    - Agr√®ge les donn√©es par "poll_date".
    - Restaure les valeurs textuelles d'origine.
 Il prend en argument Le dataframe d'entr√©e (pd.DataFrame) et retourne le dataframe transform√©.
    
"""

# Fonction pour calculer la moyenne sur les dates

def prepare_data_for_graph(df):

    # Supprimer les valeurs manquantes
    df = df.dropna()

    # Supprimer les colonnes inutiles si elles existent
    columns_to_remove = ["polling_organization", "sample_size"]
    df = df.drop(columns=[col for col in columns_to_remove if col in df.columns], errors="ignore")

    # Trouver les colonnes correspondant aux identit√©s des candidats et affiliations politiques
    identity_cols = [col for col in df.columns if col.lower().startswith("identity")]
    political_cols = [col for col in df.columns if col.lower().startswith("political_leaning")]

    # V√©rifier si ces colonnes existent
    if not identity_cols or not political_cols:
        raise ValueError("Colonnes d'identit√© ou d'affiliation politique non trouv√©es dans le DataFrame.")

    # Stocker les valeurs uniques des identit√©s et affiliations politiques
    identity_dict = {col: df[col].iloc[0] for col in identity_cols}
    political_leaning_dict = {col: df[col].iloc[0] for col in political_cols}

    # Remplacement temporaire des valeurs des colonnes identitaires et politiques par des identifiants num√©riques
    for col in identity_cols + political_cols:
        df[col] = 0  # Remplacement par une valeur neutre pour permettre l'agr√©gation

    # Agr√©gation des donn√©es par "poll_date"
    df = df.groupby("poll_date", as_index=False).mean(numeric_only=True)

    # Restauration des valeurs d'identit√© et d'affiliation politique
    for col in identity_cols:
        df[col] = identity_dict[col]

    for col in political_cols:
        df[col] = political_leaning_dict[col]

    return df

########
def clean_prediction(df):
    """
    Supprime les lignes contenant des valeurs 0 dans les colonnes commen√ßant par 'prediction'.

    Arguments:
    df -- DataFrame pandas

    Retourne:
    df_cleaned -- DataFrame nettoy√©
    """
    # S√©lectionner les colonnes qui commencent par 'prediction'
    prediction_cols = [col for col in df.columns if col.startswith("prediction")]

    # Supprimer les lignes o√π au moins une colonne 'prediction' contient 0
    df_cleaned = df[~(df[prediction_cols] == 0).any(axis=1)].reset_index()

    return df_cleaned

########

def remove_columns_before_zero_final(df):
    """
    Supprime la colonne pr√©c√©dente √† une colonne 'final' si la moyenne de cette colonne 'final' est 0.
    Cette fonction est g√©n√©rique et fonctionne avec tout DataFrame ayant des colonnes "final".

    Arguments:
    df -- DataFrame pandas

    Retourne:
    df_cleaned -- DataFrame nettoy√©
    """
    # Identifier les colonnes qui commencent par "final"
    final_cols = [col for col in df.columns if col.startswith("final")]

    # Identifier les colonnes √† supprimer
    cols_to_drop = []

    for final_col in final_cols:
        if df[final_col].mean() == 0:  # V√©rifie si la moyenne est nulle
            final_col_index = df.columns.get_loc(final_col)
            if final_col_index > 0:  # V√©rifie qu'il y a une colonne avant
                prev_col = df.columns[final_col_index - 1]
                cols_to_drop.append(prev_col)

    # Supprimer les colonnes identifi√©es
    df_cleaned = df.drop(columns=cols_to_drop, errors='ignore')

    return df_cleaned



# Charger les fichiers disponibles
data_files = {
    "Philippine": {
        "2022": "election_files/Philippine_2022_Presidential.xlsx",
        "2016": "election_files/Philippine_2016_Presidential.xlsx",
        "2010": "election_files/Philippine_2010_Presidential.xlsx"
    },
    "Poland" : {
        "2023": "election_files/Polish_2023_parliamentary.xlsx",
        "2019": "election_files/Polish_2019_parliamentary.xlsx",
        "2015": "election_files/Polish_2015_parliamentary.xlsx",
        "2011": "election_files/Polish_2011_parliamentary.xlsx",
        "2007": "election_files/Polish_2007_parliamentary.xlsx",
        "2005": "election_files/Polish_2005_parliamentary.xlsx",
        "2001": "election_files/Polish_2001_parliamentary.xlsx",
    }
}

"""#**Cr√©ation de l'interface utilisateur**"""

import streamlit as st  # interface utilisateur interactive
import matplotlib.pyplot as plt  # visualisation des donn√©es

# Interface utilisateur
st.title("üìäData Scrapers: √âvolution des pr√©dictions avant les √©lections: Philippine et Poland")

# Disposition en colonnes : 2 colonnes (Menu √† gauche, Graphique √† droite)
col1, col2 = st.columns([1, 3])

with col1:
    st.subheader("üîß Param√®tres")

    # S√©lection du pays
    selected_country = st.selectbox("üåç S√©lectionnez un pays :", list(data_files.keys()))

    # S√©lection de l'ann√©e des √©lections
    selected_year = st.selectbox("üìÖ S√©lectionnez une ann√©e d'√©lection :", list(data_files[selected_country].keys()))

    # Charger les donn√©es
    file_path = f"{data_files[selected_country][selected_year]}"

    if os.path.exists(file_path):
        df = pd.read_excel(file_path)
        data = df
        # Pr√©paration et transformation des donn√©es pour le graphique
        df = prepare_data_for_graph(df)
        df = remove_columns_before_zero_final(df)
        df = clean_prediction (df)
        # S√©lection de la p√©riode avec un calendrier interactif
        min_date = df["poll_date"].min()
        max_date = df["poll_date"].max()

        selected_dates = st.date_input(
            "üìÜ S√©lectionnez une p√©riode :",
            [min_date, max_date],
            min_value=min_date,
            max_value=max_date
        )

        # S√©lection du niveau de zoom avec un slider
        y_min, y_max = df[[col for col in df.columns if "prediction_result_candidate" in col]].min().min(), df[[col for col in df.columns if "prediction_result_candidate" in col]].max().max()
        zoom_level = st.slider("üîç Zoom sur l'axe Y (%)", min_value= 0.0, max_value=float(y_max + 40), value=(0.0, float(y_max + 5)))

# Colonne 2 : Affichage du graphique
with col2:
    if os.path.exists(file_path):
        if len(selected_dates) == 2:
            start_date, end_date = pd.to_datetime(selected_dates)
            filtered_df = df[(df["poll_date"] >= start_date) & (df["poll_date"] <= end_date)]

            if filtered_df.empty:
                st.warning("‚ö†Ô∏è Aucune donn√©e disponible pour la p√©riode s√©lectionn√©e !")
            else:
                # Graphique des pr√©dictions
                fig, ax = plt.subplots(figsize=(10, 5))

                candidate_columns = [col for col in df.columns if "prediction_result_candidate" in col]
                identity_columns = [col for col in df.columns if "identity_candidate" in col]

                for i, col in enumerate(candidate_columns):
                    candidate_name = df[identity_columns[i]].iloc[0] if identity_columns else f"Candidat {i+1}"
                    ax.plot(filtered_df["poll_date"], filtered_df[col], label=candidate_name)

                ax.set_xlabel("Date du sondage", fontsize = 12)
                ax.set_ylabel("R√©sultat de pr√©diction (%)", fontsize = 12)
                ax.set_ylim(zoom_level)  # Appliquer le zoom de l'utilisateur
                ax.grid(True, linestyle='--', alpha=0.7)
                ax.tick_params(axis='x', rotation=45)
                ax.legend()
                st.pyplot(fig)

                # Affichage des statistiques descriptives sous le graphique
                st.subheader("üìä Statistiques descriptives")
                st.write(filtered_df[candidate_columns].describe())

                # Option de t√©l√©chargement des donn√©es filtr√©es
                st.subheader("üì• T√©l√©charger les donn√©es filtr√©es")
                csv = data.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üìÇ T√©l√©charger en CSV",
                    data=csv,
                    file_name=f"predictions_{selected_year}_{selected_country}.csv",
                    mime="text/csv"
                )
    else:
        st.error("‚ùå Le fichier de donn√©es s√©lectionn√© n'existe pas.")